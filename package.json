{
  "name": "shapeteller",
  "displayName": "Shape Teller",
  "description": "Display shapes of tensors/arrays when over over a python variable by asking LLMs for help.",
  "publisher": "ruiqizhu-ricky",
  "author": "Ricky Zhu <ruiqi_zhu@outlook.com>",
  "repository": {
    "type": "git",
    "url": "https://github.com/ruiqizhu-ricky/shapeteller"
  },
  "homepage": "https://github.com/ruiqizhu-ricky/shapeteller/blob/main/README.md",
  "bugs": {
    "url": "https://github.com/ruiqizhu-ricky/shapeteller/issues",
    "email": "ruiqi_zhu@outlook.com"
  },
  "license": "MIT",
  "version": "1.0.0",
  "icon": "./icon-matrix.png",
  "engines": {
    "vscode": "^1.91.0"
  },
  "keywords": [
    "pytorch",
    "tensorflow",
    "jax",
    "tensor",
    "array",
    "shape",
    "AI",
    "Deep Learning",
    "LLM",
    "Machine Learning",
    "python"
  ],
  "categories": [
    "Debuggers",
    "Machine Learning",
    "AI"
  ],
  "activationEvents": [
    "onLanguage:python"
  ],
  "main": "./dist/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "shapeteller.turnOn",
        "title": "Shape Teller: turn on the shapeteller extension",
        "when": "editorLangId == python"
      },
      {
        "command": "shapeteller.turnOff",
        "title": "Shape Teller: turn off the shapeteller extension",
        "when": "editorLangId == python"
      }
    ],
    "configuration": {
      "title": "Shape Teller",
      "properties": {
        "shapeteller.platform.apiKey": {
          "type": "string",
          "description": "your LLM platform API key",
          "category": "platform",
          "order": 1
        },
        "shapeteller.platform.modelId": {
          "type": "string",
          "enum": [
            "gpt-4o",
            "gpt-4o-mini",
            "claude-3-5-sonnet-20240620",
            "claude-3-opus-20240229",
            "claude-3-haiku-20240307",
            "mistral-small-latest",
            "mistral-large-latest",
            "codestral-latest",
            "moonshot-v1-auto",
            "moonshot-v1-8k",
            "moonshot-v1-32k",
            "moonshot-v1-128k",
            "glm-4-plus",
            "glm-4-flash",
            "glm-4-airx",
            "glm-4-long",
            "codegeex-4"
          ],
          "category": "platform",
          "order": 1,
          "description": "which LLM to use"
        },
        "shapeteller.customised.apiEndpoint": {
          "type": "string",
          "default": null,
          "category": "customised",
          "order": 2,
          "description": "the API endpoint of your customised model (e.g., if you deployed a model locally with Ollama or vllm). If specified, it will override the `platform.apiKey` and `platform.model` settings. Please ensure that the specified endpoint is compatible with OpenAI API style."
        },
        "shapeteller.customised.modelId": {
          "type": "string",
          "description": "the model ID to use when using your specified API endpoint",
          "category": "customised",
          "order": 2
        },
        "shapeteller.general.maxToken": {
          "type": "number",
          "default": 128,
          "category": "general",
          "order": 3,
          "description": "how many tokens at most do yo allow the LLM to genereate"
        },
        "shapeteller.general.mode": {
          "type": "string",
          "enum": [
            "concise",
            "detail"
          ],
          "default": "concise",
          "description": "whether to provide detail steps on how to figure out the shapes (needs more tokens).",
          "category": "general",
          "order": 4
        },
        "shapeteller.general.isPreferVar": {
          "type": "boolean",
          "default": true,
          "description": "prefer variables (e.g. `[seq_len, vovab_size]`) over exact numbers (e.g., `[16, 50304]`).",
          "category": "general",
          "order": 5
        }
      }
    }
  },
  "scripts": {
    "compile": "npm run check-types && node esbuild.js",
    "test": "vscode-test",
    "check-types": "tsc --noEmit",
    "watch": "npm-run-all -p watch:*",
    "watch:esbuild": "node esbuild.js --watch",
    "watch:tsc": "tsc --noEmit --watch --project tsconfig.json",
    "vscode:prepublish": "npm run package",
    "package": "npm run check-types && node esbuild.js --production"
  },
  "devDependencies": {
    "@types/mocha": "^10.0.7",
    "@types/node": "20.x",
    "@types/vscode": "^1.91.1",
    "@typescript-eslint/eslint-plugin": "^7.14.1",
    "@typescript-eslint/parser": "^7.11.0",
    "@vscode/test-cli": "^0.0.9",
    "@vscode/test-electron": "^2.4.0",
    "esbuild": "^0.23.1",
    "eslint": "^8.57.0",
    "npm-run-all": "^4.1.5",
    "typescript": "^5.4.5"
  },
  "dependencies": {
    "@anthropic-ai/sdk": "^0.27.1",
    "axios": "^1.7.5",
    "openai": "^4.56.1"
  }
}
